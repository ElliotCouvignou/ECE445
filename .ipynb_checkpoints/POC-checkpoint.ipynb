{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS CELL IS JUST FOR 3RD PARTY FUNCTIONS ### \n",
    "def sound( x, rate=8000, label=''):\n",
    "    from IPython.display import display, Audio, HTML\n",
    "    if label is '':\n",
    "        display( Audio( x, rate=rate))\n",
    "    else:\n",
    "        display( HTML( \n",
    "        '<style> table, th, td {border: 0px; }</style> <table><tr><td>' + label + \n",
    "        '</td><td>' + Audio( x, rate=rate)._repr_html_()[3:] + '</td></tr></table>'\n",
    "        ))\n",
    "        \n",
    "        ## carry over code placed here to reduce clutter\n",
    "\n",
    "\n",
    "# i did make this tho\n",
    "def stft( input_sound, dft_size, hop_size, zero_pad, window=1.0):\n",
    "    length = len(input_sound)\n",
    "    \n",
    "    # Part1. splitting into frames\n",
    "    FrameAmount = math.ceil((length) / hop_size) + 1\n",
    "    slices = np.arange(dft_size * FrameAmount).reshape(dft_size, FrameAmount)\n",
    "    # set slices into array\n",
    "    for i in range(FrameAmount):\n",
    "        start = i * hop_size\n",
    "        end = start + dft_size\n",
    "        \n",
    "        data = input_sound[start:end]\n",
    "        \n",
    "        # input too short... need to zero padd end\n",
    "        if(data.shape[0] < dft_size):\n",
    "            zero_padd = np.zeros(dft_size - data.shape[0])\n",
    "            data = np.hstack((data, zero_padd))\n",
    "           \n",
    "        slices[:,i] = data * window\n",
    "        \n",
    "    #  Part2. Do fft of input slices        \n",
    "    size = dft_size+zero_pad   \n",
    "    if(size%2 ==0):\n",
    "        NumBins = ((size) // 2) + 1\n",
    "    else:\n",
    "        NumBins = ((size) + 1) // 2\n",
    "    \n",
    "    NumBins = int(NumBins)\n",
    "    f = np.arange(NumBins * FrameAmount, dtype=np.complex_).reshape(NumBins, FrameAmount)   \n",
    "    f[:,:] = 0. + 0.j\n",
    "    \n",
    "    for i in range(FrameAmount):\n",
    "        f[:,i] = np.fft.rfft(slices[:,i], size)      \n",
    "\n",
    "    # Return a complex-valued spectrogram (frequencies x time)\n",
    "    return f\n",
    "\n",
    "def FormatAxis(specArray, sr, time):\n",
    "    length = specArray.shape[1]\n",
    "    numbins = specArray.shape[0]\n",
    "    timeline = np.linspace(0, time, length)\n",
    "    freqline = np.linspace(0, sr/2, numbins)\n",
    "    #freqline = np.fft.fftfreq(numbins, d=1./sr)\n",
    "    return timeline, freqline\n",
    "\n",
    "\n",
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "       return v\n",
    "    return v / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 WAV header indicates an unsupported format.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\api_core\\grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\grpc\\_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    825\u001b[0m                                       wait_for_ready, compression)\n\u001b[1;32m--> 826\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\grpc\\_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"WAV header indicates an unsupported format.\"\n\tdebug_error_string = \"{\"created\":\"@1582145987.486000000\",\"description\":\"Error received from peer ipv4:172.217.4.202:443\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"WAV header indicates an unsupported format.\",\"grpc_status\":3}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-a2b285975f65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'case2filt.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m \u001b[0mtranscript\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_long_running_recognize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage_uri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-a2b285975f65>\u001b[0m in \u001b[0;36msample_long_running_recognize\u001b[1;34m(storage_uri)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"uri\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstorage_uri\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0moperation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong_running_recognize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu\"Waiting for transcription to complete...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\cloud\\speech_v1\\gapic\\speech_client.py\u001b[0m in \u001b[0;36mlong_running_recognize\u001b[1;34m(self, config, audio, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    341\u001b[0m         )\n\u001b[0;32m    342\u001b[0m         operation = self._inner_api_calls[\"long_running_recognize\"](\n\u001b[1;32m--> 343\u001b[1;33m             \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m         )\n\u001b[0;32m    345\u001b[0m         return google.api_core.operation.from_gapic(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"metadata\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\api_core\\retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                 \u001b[0mon_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m             )\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\api_core\\retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\api_core\\timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[1;34m\"\"\"Wrapped function that adds timeout.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"timeout\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\api_core\\grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: 400 WAV header indicates an unsupported format."
     ]
    }
   ],
   "source": [
    "## REAL POC CELL ##\n",
    "\n",
    "\"\"\"\n",
    "Created on Mon Feb 10 16:36:55 2020\n",
    "No stealy \n",
    "@author: ecouv\n",
    "\"\"\"\n",
    "\n",
    "from google.cloud import speech_v1\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "import copy\n",
    "\n",
    "    \n",
    "def sample_long_running_recognize(storage_uri):\n",
    "    \"\"\"\n",
    "    Print start and end time of each word spoken in audio file from Cloud Storage\n",
    "\n",
    "    Args:\n",
    "      storage_uri URI for audio file in Cloud Storage, e.g. gs://[BUCKET]/[FILE]\n",
    "    \"\"\"\n",
    "\n",
    "    client = speech_v1.SpeechClient()\n",
    "\n",
    "    # storage_uri = 'gs://cloud-samples-data/speech/brooklyn_bridge.flac'\n",
    "\n",
    "    # When enabled, the first result returned by the API will include a list\n",
    "    # of words and the start and end time offsets (timestamps) for those words.\n",
    "    enable_word_time_offsets = True\n",
    "\n",
    "    # The language of the supplied audio\n",
    "    language_code = \"en-US\"\n",
    "    config = {\n",
    "        \"enable_word_time_offsets\": enable_word_time_offsets,\n",
    "        \"language_code\": language_code,\n",
    "    }\n",
    "    audio = {\"uri\": storage_uri}\n",
    "\n",
    "    operation = client.long_running_recognize(config, audio)\n",
    "\n",
    "    print(u\"Waiting for transcription to complete...\")\n",
    "    response = operation.result()\n",
    "\n",
    "    # The first result includes start and end time word offsets\n",
    "    result = response.results[0]\n",
    "    # First alternative is the most probable result\n",
    "    alternative = result.alternatives[0]\n",
    "    print(u\"Transcription complete...\")\n",
    " \n",
    "        \n",
    "    return alternative.words\n",
    "\n",
    "\n",
    "#\n",
    "# real POC stuff here, given new transcript with new times, shift audio\n",
    "# shifted audio is overlaped over currently processing audio \n",
    "#\n",
    "def ShiftAudioOverlap(OldTranscript, NewTranscript, Input_audio, sampling_rate):\n",
    "    \n",
    "    output = copy.deepcopy(Input_audio)\n",
    "    \n",
    "    # go through each word, find timeshift, add zero's within if pos and cut if neg\n",
    "    for i in range(len(OldTranscript)):\n",
    "        oldword = OldTranscript[i]\n",
    "        newword = NewTranscript[i]\n",
    "        oldstart = oldword.start_time.nanos /10**9 + oldword.start_time.seconds\n",
    "        newstart = newword.start_time.nanos /10**9 + newword.start_time.seconds\n",
    "        oldend = oldword.end_time.nanos /10**9\n",
    "        \n",
    "        timelength = oldend-oldstart\n",
    "        framelength = abs(int(timelength * sampling_rate))\n",
    "        \n",
    "        # timeshift = change(framestart)\n",
    "        timeshift = newstart - oldstart\n",
    "        N = int(timeshift * sampling_rate)  # sample shift\n",
    "         \n",
    "        if(N != 0):\n",
    "            oldstartslice = int(oldstart * sampling_rate)\n",
    "            newstartslice = int(newstart *sampling_rate)\n",
    "            \n",
    "            if(timeshift > 0 and newstartslice+framelength >= len(Input_audio)):\n",
    "                pad = newstartslice+framelength - len(Input_audio) + 1\n",
    "                Input_audio = np.hstack((Input_audio, np.zeros(pad)))\n",
    "                output = np.hstack((output, np.zeros(pad)))\n",
    "            \n",
    "            \n",
    "            #slice out\n",
    "            word = Input_audio[oldstartslice:(oldstartslice+framelength)]\n",
    "            output[oldstartslice:(oldstartslice+framelength)] = 0 # set before spot to 0 for now \n",
    "            \n",
    "            #add word into new spot\n",
    "            output[newstartslice:(newstartslice+framelength)] += word\n",
    "        \n",
    "    return output\n",
    "\n",
    "#\n",
    "# \n",
    "# SAME AS ABOVE BUT ONLY 1 word (for real-time update) \n",
    "#\n",
    "def ShiftAudioOverlapWord(oldword, newword, Input_audio, sampling_rate):\n",
    "    \n",
    "    output = copy.deepcopy(Input_audio)\n",
    "    \n",
    "    # go through each word, find timeshift, add zero's within if pos and cut if neg\n",
    "\n",
    "    oldstart = oldword.start_time.nanos /10**9 + oldword.start_time.seconds\n",
    "    newstart = newword.start_time.nanos /10**9 + newword.start_time.seconds\n",
    "    oldend = oldword.end_time.nanos /10**9\n",
    "    \n",
    "    timelength = oldend-oldstart\n",
    "    framelength = abs(int(timelength * sampling_rate))\n",
    "    \n",
    "    # timeshift = change(framestart)\n",
    "    timeshift = newstart - oldstart\n",
    "    N = int(timeshift * sampling_rate)  # sample shift\n",
    "     \n",
    "    if(N != 0):\n",
    "        oldstartslice = int(oldstart * sampling_rate)\n",
    "        newstartslice = int(newstart *sampling_rate)\n",
    "\n",
    "        if(newstartslice+framelength >= len(Input_audio)):\n",
    "            pad = newstartslice+framelength - len(Input_audio) + 1\n",
    "            Input_audio = np.hstack((Input_audio, np.zeros(pad)))\n",
    "            output = np.hstack((output, np.zeros(pad)))\n",
    "        \n",
    "        \n",
    "        #slice out\n",
    "        word = Input_audio[oldstartslice:(oldstartslice+framelength)]\n",
    "        output[oldstartslice:(oldstartslice+framelength)] = 0 # set before spot to 0 for now \n",
    "        \n",
    "        #add word into new spot\n",
    "        output[newstartslice:(newstartslice+framelength)] += word\n",
    "        \n",
    "    return output\n",
    "\n",
    "#\n",
    "# \n",
    "# instead of overlap, delete removed part and place in new section (NO OVERLAP)\n",
    "# req7\n",
    "#\n",
    "def ShiftAudioWord(oldword, newword, Input_audio, sampling_rate):\n",
    "    \n",
    "    output = copy.deepcopy(Input_audio)\n",
    "    \n",
    "    # go through each word, find timeshift, add zero's within if pos and cut if neg\n",
    "\n",
    "    oldstart = oldword.start_time.nanos /10**9 + oldword.start_time.seconds\n",
    "    newstart = newword.start_time.nanos /10**9 + newword.start_time.seconds\n",
    "    oldend = oldword.end_time.nanos /10**9\n",
    "    \n",
    "    timelength = oldend-oldstart\n",
    "    framelength = abs(int(timelength * sampling_rate))\n",
    "    \n",
    "    # timeshift = change(framestart)\n",
    "    timeshift = newstart - oldstart\n",
    "    N = int(timeshift * sampling_rate)  # sample shift\n",
    "     \n",
    "    if(N != 0):\n",
    "        oldstartslice = int(oldstart * sampling_rate)\n",
    "        newstartslice = int(newstart *sampling_rate)\n",
    "\n",
    "        if(newstartslice+framelength >= len(Input_audio)):\n",
    "            pad = newstartslice+framelength - len(Input_audio) + 1\n",
    "            Input_audio = np.hstack((Input_audio, np.zeros(pad)))\n",
    "            output = np.hstack((output, np.zeros(pad)))\n",
    "        \n",
    "        \n",
    "        #slice out\n",
    "        word = Input_audio[oldstartslice:(oldstartslice+framelength)]\n",
    "        output[oldstartslice:(oldstartslice+framelength)] = 0 # set before spot to 0 for now \n",
    "        \n",
    "        #add word into new spot\n",
    "        \n",
    "        output[newstartslice:(newstartslice+framelength)] += word\n",
    "        \n",
    "    return output\n",
    "    \n",
    "# shifts by unit of time in seconds\n",
    "def ShiftTranscriptWord(transcript, index, timeshift):\n",
    "    \n",
    "    secs = int(timeshift)\n",
    "    nanos = int((timeshift - secs) * 10**9)\n",
    "    \n",
    "    word = transcript[index]\n",
    "    \n",
    "    if(word.start_time.nanos + nanos >= 10**9):\n",
    "        secs += 1\n",
    "    if(word.end_time.nanos + nanos >= 10**9):\n",
    "        secs += 1\n",
    "    \n",
    "    word.start_time.seconds += secs\n",
    "    word.end_time.seconds += secs\n",
    "\n",
    "    word.start_time.nanos = (word.start_time.nanos + nanos ) % 10**9\n",
    "    word.end_time.nanos = (word.end_time.nanos + nanos ) % 10**9\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#### START ####\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"JSON/My First Project-1534988de9b5.json\"\n",
    "\n",
    "storage_uri = 'gs://ringr_audio/venv/RawAudio/case2.wav'\n",
    "    \n",
    "    \n",
    "sr, case2 = wavfile.read('case2.wav')  \n",
    "transcript = sample_long_running_recognize(storage_uri)\n",
    "\n",
    "\n",
    "# create deepcopy to prevent reference copying\n",
    "newtrans = copy.deepcopy(np.asarray(transcript))\n",
    "\n",
    "\n",
    "# MAKE NEW TRANSCRIPT\n",
    "\n",
    "# shift 'top' word by 3 seconds\n",
    "ShiftTranscriptWord(newtrans, 0, 0)\n",
    "ShiftTranscriptWord(newtrans, 1, 2)\n",
    "ShiftTranscriptWord(newtrans, 2, 0)\n",
    "ShiftTranscriptWord(newtrans, 3, 0)\n",
    "ShiftTranscriptWord(newtrans, 4, 0)\n",
    "ShiftTranscriptWord(newtrans, 5, 0)\n",
    "ShiftTranscriptWord(newtrans, 6, 1)\n",
    "\n",
    "\n",
    "# get new audio from new transcript\n",
    "newsoundindi = ShiftAudioOverlapWord(transcript[1], newtrans[1], case2, sr)\n",
    "newsoundindi = ShiftAudioOverlapWord(transcript[6], newtrans[6], newsoundindi, sr)\n",
    "newsound = ShiftAudioOverlap(transcript, newtrans, case2, sr)\n",
    "\n",
    "\n",
    "## plot spectrograms with audio widget\n",
    "sound(case2, sr, 'old sound')\n",
    "spec = stft(input_sound=case2, dft_size=256, hop_size=64, zero_pad=256, window=signal.hann(256))\n",
    "t,f = FormatAxis(spec, sr, len(case2)/sr)\n",
    "plt.clf()\n",
    "plt.pcolormesh(t, f, abs(spec)**0.2)\n",
    "plt.title('Raw Audio Spectrogram')\n",
    "plt.xlabel('time (seconds)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sound(newsound, sr, 'new sound')\n",
    "spec = stft(input_sound=newsound, dft_size=256, hop_size=64, zero_pad=256, window=signal.hann(256))\n",
    "t,f = FormatAxis(spec, sr, len(newsound)/sr)\n",
    "plt.clf()\n",
    "plt.pcolormesh(t, f, abs(spec)**0.2)\n",
    "plt.title('new sound Audio Spectrogram')\n",
    "plt.xlabel('time (seconds)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.show()\n",
    "\n",
    "sound(newsoundindi, sr, 'new sound (using individual function)')\n",
    "spec = stft(input_sound=newsoundindi, dft_size=256, hop_size=64, zero_pad=256, window=signal.hann(256))\n",
    "t,f = FormatAxis(spec, sr, len(newsoundindi)/sr)\n",
    "plt.clf()\n",
    "plt.pcolormesh(t, f, abs(spec)**0.2)\n",
    "plt.title('new sound (using individual function) Audio Spectrogram')\n",
    "plt.xlabel('time (seconds)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
